{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN with Atari Space Invaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> .rendered_html code { \n",
       "    padding: 2px 4px;\n",
       "    color: #c7254e;\n",
       "    background-color: #f9f2f4;\n",
       "    border-radius: 4px;\n",
       "} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bit of formatting because inline code is not styled very good by default:\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"<style> .rendered_html code { \n",
    "    padding: 2px 4px;\n",
    "    color: #c7254e;\n",
    "    background-color: #f9f2f4;\n",
    "    border-radius: 4px;\n",
    "} </style>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get necessary libraries\n",
    "import tensorflow as tf   \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np           \n",
    "import retro                 \n",
    "\n",
    "from skimage import transform \n",
    "from skimage.color import rgb2gray \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Environment from OpenAI Retro\n",
    "Note: Need to download <a href=\"http://www.atarimania.com/rom_collection_archive_atari_2600_roms.html\">Atari ROM</a> before initializing gym environment\n",
    "\n",
    "\n",
    "\n",
    "Command Line to Import ROM: python -m retro.import ./path/to/your/ROMs/directory/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space:  8\n",
      "Observation space:  Box(210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "env = retro.make(game='SpaceInvaders-Atari2600')\n",
    "env.reset()                    \n",
    "\n",
    "print(\"Action space: \", env.action_space.n)\n",
    "print(\"Observation space: \", env.observation_space)\n",
    "\n",
    "# Here we create an hot encoded version of our actions\n",
    "possible_actions = np.array(np.identity(env.action_space.n,dtype=int).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Preprocessing Functions\n",
    "- RGB to Grayscale\n",
    "- Crop Frame\n",
    "- Normalize Pixel Values\n",
    "- Resize Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    # Greyscale frame \n",
    "    gray = rgb2gray(frame)\n",
    "    \n",
    "    # Crop the screen (remove the part below the player)\n",
    "    # [Up: Down, Left: right]\n",
    "    cropped_frame = gray[8:-12,4:-12]\n",
    "    \n",
    "    # Normalize Pixel Values\n",
    "    normalized_frame = cropped_frame/255.0\n",
    "    \n",
    "    # Resize\n",
    "    preprocessed_frame = transform.resize(normalized_frame, [110,84])\n",
    "    \n",
    "    return preprocessed_frame # 110x84x1 frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Stack Frames to Give a Sense of Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_size = 4 \n",
    "\n",
    "# Initialize deque with zero-images one array for each image\n",
    "stacked_frames  =  deque([np.zeros((110,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
    "\n",
    "def stack_frames(stacked_frames, state, is_new_episode):\n",
    "    # Preprocess frame\n",
    "    frame = preprocess_frame(state)\n",
    "    \n",
    "    if is_new_episode:\n",
    "        # Clear our stacked_frames\n",
    "        stacked_frames = deque([np.zeros((110,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
    "        \n",
    "        # Because we're in a new episode, copy the same frame 4x\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        \n",
    "        # Stack the frames\n",
    "        stacked_state = np.stack(stacked_frames, axis=2)\n",
    "        \n",
    "    else:\n",
    "        # Append frame to deque, automatically removes the oldest frame\n",
    "        stacked_frames.append(frame)\n",
    "\n",
    "        # Build the stacked state (first dimension specifies different frames)\n",
    "        stacked_state = np.stack(stacked_frames, axis=2) \n",
    "    \n",
    "    return stacked_state, stacked_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL HYPERPARAMETERS\n",
    "state_size = [110, 84, 4]      \n",
    "action_size = env.action_space.n \n",
    "learning_rate =  0.001\n",
    "\n",
    "# TRAINING HYPERPARAMETERS\n",
    "total_episodes = 50          \n",
    "max_steps = 50000              \n",
    "batch_size = 64               \n",
    "\n",
    "# Exploration parameters for epsilon greedy strategy\n",
    "explore_start = 1.0            \n",
    "explore_stop = 0.01             \n",
    "decay_rate = 0.001\n",
    "\n",
    "# Q learning hyperparameters\n",
    "gamma = 0.9                  # Discounting rate\n",
    "\n",
    "# MEMORY HYPERPARAMETERS\n",
    "pretrain_length = batch_size # Number of experiences stored in the Memory when initialized for the first time\n",
    "memory_size = 1000000        # Number of experiences the Memory can keep\n",
    "\n",
    "# PREPROCESSING HYPERPARAMETERS\n",
    "stack_size = 4               # Number of frames stacked\n",
    "\n",
    "# MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE TRAINED AGENT\n",
    "training = False\n",
    "\n",
    "# TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n",
    "episode_render = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Deep Q-learning Model\n",
    "1. Stack 4 frames as input\n",
    "2. Add 3 Convolutional Layers\n",
    "3. Flatten Layer\n",
    "4. Add 2 Fully Connected Layers\n",
    "5. Outputs a Q Value for each Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 84, 84, 4)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 20, 20, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          16448     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 586,408\n",
      "Trainable params: 586,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "inputs = keras.Input(shape=(84,84,4), dtype=\"float32\", name=\"inputs\")\n",
    "        \n",
    "conv1 = layers.Conv2D(32, 8, strides=(4,4), activation='elu')(inputs)\n",
    "conv2 = layers.Conv2D(64, 4, strides=(2,2), activation='elu')(conv1)\n",
    "conv3 = layers.Conv2D(64, 2, strides=(2,2), activation='elu')(conv2)\n",
    "        \n",
    "flat = layers.Flatten()(conv3)\n",
    "        \n",
    "fc = layers.Dense(512, activation='elu')(flat)\n",
    "out = layers.Dense(action_size)(fc)\n",
    "        \n",
    "model = keras.Model(inputs=inputs, outputs=out) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actions = tf.Variable(tf.zeros(shape=(None, action_size)), name=\"actions\")\n",
    "            \n",
    "# Remember that target_Q is the R(s,a) + ymax Qhat(s', a')\n",
    "#targetQ = tf.Variable(tf.zeros(shape=(None)), name=\"target\")\n",
    "                     \n",
    "# Q is our predicted Q value.\n",
    "#Q = tf.math.reduce_mean(tf.math.multiply(out, actions))\n",
    "            \n",
    "# The loss is the difference between our predicted Q_values and the Q_target\n",
    "# Sum(Qtarget - Q)^2\n",
    "#loss = tf.math.reduce_mean(tf.math.square(target_Q - Q))\n",
    "#optimizer = keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLv2",
   "language": "python",
   "name": "rlv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
